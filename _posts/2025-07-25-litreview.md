---
title: 'What We Know and What We Don’t Know About Combatting Misinformation'
date: 2025-07-25
permalink: /posts/2025/litreview/
layout: single
tags:
  - misinformation interventions
  - scoping review
  - bibliometrics
excerpt: >-
  <img src="/assets/images/articles_category.png" alt="Interventions Studied"
       style="width:70%;height:auto;margin-bottom:0.6em;">
  <br>
  We reviewed over 450 academic papers on misinformation interventions across user, platform,
  and policy levels. Using bibliometric analysis, we discovered what’s been studied the most 
  and the overlooked strategies that deserve more attention.
---

<figure style="text-align: center; margin-top: 1em; margin-bottom: 1em;">
  <img src="/assets/images/articles_category.png" alt="Interventions Studied" style="width:70%; height:auto;">
  <figcaption style="font-size: 0.9em; color: #555; margin-top: 0.5em;">
    Intervention categories studied in misinformation research over the past 20 years.
  </figcaption>
</figure>

Over the last twenty years, researchers have proposed many strategies to combat misinformation, including fact-checking, media literacy campaigns, and warning labels. But which interventions get studied the most, and which ones actually work? We conducted a bibliometric review of over 450 papers on misinformation strategies at the user, platform, and policy levels. 

<!-- more -->

Our main findings: 
<ol>
  <li>
    <b>Most research is on the same few interventions</b><br>
   Most research focuses on fact-checking, debunking, and media literacy, while other promising strategies, such as redirecting users, account demonetization, or improving user reporting tools, remain largely overlooked. 
  </li>
  <li>
    <b>The field remains relatively siloed, although cross-disciplinary collaboration is growing.</b><br>
    Research on misinformation spans multiple disciplines, encompassing fields such as communications, psychology, computer science, and political science. However, authors still mostly publish in journals within their primary disciplines. 
  </li>
  <li>
    <b>Most papers study effectiveness without considering user acceptance.</b><br>
    Nearly 90% of papers assess the effectiveness of interventions, but only 9% study user acceptance. This suggests we may know which strategies could work in theory, but we don’t know if people are willing to adopt them. Without user buy-in, platforms are unlikely to implement these interventions.
  </li>
  <li>
    <b>Some findings on intervention effectiveness are inconsistent</b><br>
    Even among the most researched interventions, results vary. For example, some studies show inoculation games (e.g., Bad News) are effective, but others have found minimal or no long-term effects. This highlights the need for more rigorous, standardized evaluation methods.
  </li>
</ol>
If we want to counter the spread of misinformation, we need solutions that are not only effective in lab settings but also accepted, usable, and scalable in real-world environments. Future work should focus on interdisciplinary collaboration, investigating understudied intervention types, and assessing interventions not only based on effectiveness but also on user acceptance.

[Full paper](https://workshop-proceedings.icwsm.org/pdf/2025_10.pdf)<br>
